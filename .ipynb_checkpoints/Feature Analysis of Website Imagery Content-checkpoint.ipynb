{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis of Website Imagery Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joostin/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import os\n",
    "import pymongo\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import pprint\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.core.display import display, HTML\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "from gridfs import GridFS\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy.core.umath_tests import inner1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_training = 0.85\n",
    "n_estimators = 1000\n",
    "client = MongoClient(open('../../db.txt', encoding='UTF-8').read())\n",
    "db = client.knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        _id  averageBlue  averageGreen  averageRed colorCount  \\\n",
      "0  5bd5202204c0591b776aeb2e     1.750000      1.750000    1.750000          1   \n",
      "1  5bd5203804c0591b776aeb2f     1.326043      1.339848    1.367402        290   \n",
      "2  5bd5267d04c0591b776aeb30     1.614444      1.593742    1.527081         39   \n",
      "3  5bd5268104c0591b776aeb31     1.593981      1.563667    1.461685         85   \n",
      "4  5bddd8d8fcab5fa6b04cb12c     1.666679      1.663924    1.660496         91   \n",
      "\n",
      "  label mostPopular                                                url  \\\n",
      "0     y         777         https://id.pausd.org/portal/p/applications   \n",
      "1     m         777                           https://www.youtube.com/   \n",
      "2     y         777  https://www.kaggle.com/juustiiiin/textscraper/...   \n",
      "3     y         777                            https://www.kaggle.com/   \n",
      "4     y         777  https://github.com/boovines/dataLabeler/blob/m...   \n",
      "\n",
      "   educational  \n",
      "0            1  \n",
      "1            0  \n",
      "2            1  \n",
      "3            1  \n",
      "4            1  \n"
     ]
    }
   ],
   "source": [
    "labels = db.labels\n",
    "\n",
    "data = labels.find({'colorCount':{'$ne':None}}, {'_id':1,'url':1,'label':1,'colorCount':1,'mostPopular':1,'averageRed':1,'averageGreen':1,'averageBlue':1})\n",
    "\n",
    "table = pd.DataFrame([item for item in data])\n",
    "table = table.assign(educational=table['label'].map(lambda r: 1 if r=='y' else 0))\n",
    "print(table.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        _id  averageBlue  averageGreen  averageRed colorCount  \\\n",
      "0  5bd5202204c0591b776aeb2e     1.750000      1.750000    1.750000          1   \n",
      "1  5bd5203804c0591b776aeb2f     1.326043      1.339848    1.367402        290   \n",
      "2  5bd5267d04c0591b776aeb30     1.614444      1.593742    1.527081         39   \n",
      "3  5bd5268104c0591b776aeb31     1.593981      1.563667    1.461685         85   \n",
      "4  5bddd8d8fcab5fa6b04cb12c     1.666679      1.663924    1.660496         91   \n",
      "\n",
      "  label mostPopular                                                url  \\\n",
      "0     y         777         https://id.pausd.org/portal/p/applications   \n",
      "1     m         777                           https://www.youtube.com/   \n",
      "2     y         777  https://www.kaggle.com/juustiiiin/textscraper/...   \n",
      "3     y         777                            https://www.kaggle.com/   \n",
      "4     y         777  https://github.com/boovines/dataLabeler/blob/m...   \n",
      "\n",
      "   educational                                      featureVector  \n",
      "0            1                         [1.75, 1.75, 1.75, 1, 777]  \n",
      "1            0  [1.3674016873278236, 1.3398476239669421, 1.326...  \n",
      "2            1  [1.5270810688405798, 1.5937423573369565, 1.614...  \n",
      "3            1  [1.4616849566691785, 1.5636673417483045, 1.593...  \n",
      "4            1  [1.660496116703392, 1.6639238667284322, 1.6666...  \n",
      "(913, 10)\n"
     ]
    }
   ],
   "source": [
    "def vectorizeMe(averageRed, averageGreen, averageBlue, colorCount, mostPopular):\n",
    "    return [float(averageRed), float(averageGreen), float(averageBlue), int(colorCount), int(mostPopular)]\n",
    "\n",
    "interesting_rows = [r.tolist() for r in table[['averageRed','averageGreen', 'averageBlue','colorCount', 'mostPopular'][0:5]].values]\n",
    "\n",
    "vectorized_rows = [vectorizeMe(row[0],row[1],row[2],row[3],row[4]) for row in interesting_rows]\n",
    "\n",
    "table = table.assign(featureVector=vectorized_rows)\n",
    "\n",
    "print(table.head())\n",
    "print(table.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    row_count = int(percent_training*float(table.shape[0]))\n",
    "    training_data = table.sample(n=row_count)\n",
    "#    training_data.info()\n",
    "#    training_data.head(10)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_data(training_data):\n",
    "    training_data_ids = [_id for _id in training_data._id]\n",
    "    testing_data = table[~table['_id'].isin(training_data_ids)]\n",
    "#    testing_data.info()\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(training_data):\n",
    "    forest = RandomForestClassifier(n_estimators=n_estimators) \n",
    "    forest = forest.fit(np.array([ np.array(row) for row in training_data[\"featureVector\"]]), training_data[\"educational\"] )\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(testing_data,forest):\n",
    "    result = forest.predict(np.array([ np.array(row) for row in testing_data[\"featureVector\"]]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(testing_data,result):\n",
    "    output = pd.DataFrame( data={\"actual\":testing_data['educational'], \"predicted\":result})\n",
    "\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "\n",
    "    actual = output['actual'].tolist()\n",
    "    predicted = output['predicted'].tolist()\n",
    "    event_count = float(output.shape[0]);\n",
    "\n",
    "    for x in range(output.shape[0]):\n",
    "        a = actual[x]\n",
    "        p = predicted[x]\n",
    "        if a == 1 and p == 1:\n",
    "            true_positives += 1\n",
    "        elif a == 1 and p == 0:\n",
    "            false_negatives += 1\n",
    "        elif a == 0 and p == 1:\n",
    "            false_positives += 1\n",
    "        elif a == 0 and p == 0:\n",
    "            true_negatives += 1\n",
    "    \n",
    "    return float(true_positives)/event_count *100, float(true_negatives)/event_count * 100, float(false_positives)/event_count* 100, float(false_negatives)/event_count * 100, event_count\n",
    "            \n",
    "            \n",
    "#display(HTML(\"\"\"\n",
    "#    <h3>Confusion Matrix</h3>\n",
    "#    <table>\n",
    "#        <tr>\n",
    "#            <th><b>Confusion Matrix Cell</b></th><th>Term (P)</th><th>Value (P)</th>\n",
    "#        </tr>\n",
    "#        <tr>\n",
    "#            <th>True Positive</th><th>Sensitivity</th><td>%1.0f%%</td>\n",
    "#        </tr>\n",
    "#        <tr>\n",
    "#            <th>False Positive</th><th>Fall-Out Rate</th><td>%1.0f%%</td>\n",
    "#        </tr>\n",
    "#        <tr>\n",
    "#            <th>False Negative</th><th>Miss Rate</th><td>%1.0f%%</td>\n",
    "#        </tr>\n",
    "#        <tr>\n",
    "#            <th>True Negative</th><th>Specificity</th><td>%1.0f%%</td>\n",
    "#        </tr>\n",
    "#    </table>\n",
    "#\"\"\" % (float(true_positives) / eventCount *100, float(false_positives) /eventCount*100, float(false_negatives)/eventCount*100,float(true_negatives)/eventCount*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8.75912408759124,\n",
      "  51.82481751824818,\n",
      "  14.5985401459854,\n",
      "  24.817518248175183,\n",
      "  137.0),\n",
      " (10.948905109489052,\n",
      "  52.55474452554745,\n",
      "  10.218978102189782,\n",
      "  26.277372262773724,\n",
      "  137.0),\n",
      " (17.51824817518248,\n",
      "  42.33576642335766,\n",
      "  12.408759124087592,\n",
      "  27.73722627737226,\n",
      "  137.0),\n",
      " (13.138686131386862,\n",
      "  45.25547445255474,\n",
      "  10.948905109489052,\n",
      "  30.656934306569344,\n",
      "  137.0),\n",
      " (13.86861313868613,\n",
      "  48.9051094890511,\n",
      "  15.328467153284672,\n",
      "  21.897810218978105,\n",
      "  137.0),\n",
      " (13.86861313868613,\n",
      "  41.605839416058394,\n",
      "  18.97810218978102,\n",
      "  25.547445255474454,\n",
      "  137.0),\n",
      " (15.328467153284672,\n",
      "  48.9051094890511,\n",
      "  6.569343065693431,\n",
      "  29.1970802919708,\n",
      "  137.0),\n",
      " (12.408759124087592,\n",
      "  55.47445255474452,\n",
      "  10.948905109489052,\n",
      "  21.16788321167883,\n",
      "  137.0),\n",
      " (15.328467153284672,\n",
      "  45.98540145985402,\n",
      "  20.437956204379564,\n",
      "  18.248175182481752,\n",
      "  137.0),\n",
      " (11.678832116788321,\n",
      "  49.63503649635037,\n",
      "  18.248175182481752,\n",
      "  20.437956204379564,\n",
      "  137.0)]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    training_data = get_training_data()\n",
    "    testing_data = get_testing_data(training_data)\n",
    "    model = training_model(training_data)\n",
    "    result = get_result(testing_data, model)\n",
    "    confusion_matrix = create_confusion_matrix(testing_data, result)\n",
    "    results.append(confusion_matrix)\n",
    "pprint.pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
